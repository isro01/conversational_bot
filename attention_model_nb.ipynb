{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/isro/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/isro/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/isro/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/isro/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/isro/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/isro/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/isro/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/isro/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/isro/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/isro/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/isro/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/isro/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply , Embedding\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "\n",
    "# from faker import Faker\n",
    "# import random\n",
    "# from tqdm import tqdm\n",
    "# from babel.dates import format_date\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        \n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "            \n",
    "    return words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, word_to_vec_map = read_glove_vecs('glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(word_to_vec_map[\"father\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I'm coming.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_sentences=[]\n",
    "\n",
    "filepath = 'inp_dat.txt'\n",
    "with open(filepath) as fp:\n",
    "    line = fp.readline()\n",
    "    cnt = 1\n",
    "    while cnt <3000 :\n",
    "        line = fp.readline()\n",
    "        if cnt >15:\n",
    "            input_sentences.append(line)\n",
    "        cnt+=1\n",
    "print(input_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'im'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wordcleaner(word):\n",
    "    temp=\"\"\n",
    "    for char in word:\n",
    "#         print(char)\n",
    "        if char!= \",\" and char!= \"!\" and char!= \"?\" and char!= \".\" and char!= \"'\" and char!= \"-\":\n",
    "#         if char!=',':\n",
    "            temp+=char\n",
    "    return temp\n",
    "wordcleaner(\"i'm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_emb_list=[]\n",
    "\n",
    "for l in input_sentences:\n",
    "#     print(l)\n",
    "    temp=[]\n",
    "    for word in l.lower().split():\n",
    "#         print(word)\n",
    "        word = wordcleaner(word)\n",
    "#         if word!=\"\":\n",
    "        w = word_to_vec_map.get(word)\n",
    "        temp.append(w)\n",
    "#         print(np.shape(temp))\n",
    "    post_emb_list.append(temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "context = np.zeros((10,max_len))\n",
    "response = np.zeros((10,max_len))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add = np.zeros((1,50))\n",
    "# for l in post_emb_list:\n",
    "#     while np.shape(l)!=(10,):\n",
    "#         l.append(add)\n",
    "    \n",
    "# print(np.shape(post_emb_list[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 19 401 156   7 282  33 228 637  10  44  80   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "(2984, 20)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 100\n",
    "max_length = 20\n",
    "trunc_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(input_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(input_sentences)\n",
    "padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type,padding=\"post\")\n",
    "print(padded[6])\n",
    "print(np.shape(padded))\n",
    "\n",
    "index_word = {}\n",
    "for word , index in word_index.items():\n",
    "    index_word[index] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20)\n",
      "[143. 403.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.]\n",
      "[ 12. 343.  19. 518. 519.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "index=0\n",
    "for idx in range(0,20,2):\n",
    "    context[index,:] = padded[idx]\n",
    "    response[index,:] = padded[idx+1]\n",
    "    index +=1\n",
    "    \n",
    "print(np.shape(context))\n",
    "print(context[6])\n",
    "print(response[0])\n",
    "response = list(response.swapaxes(0,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "embeddings_index = {}\n",
    "f = open( 'glove.6B.50d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 50))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            50,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=20,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx = 20\n",
    "repeator = RepeatVector(Tx)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor1 = Dense(20, activation = \"tanh\")\n",
    "densor2 = Dense(1, activation = \"relu\")\n",
    "activator = Activation(softmax, name='attention_weights') # We are using a custom softmax(axis = 1) loaded in this notebook\n",
    "dotor = Dot(axes = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention(a, s_prev):\n",
    "    \"\"\"\n",
    "    Performs one step of attention: Outputs a context vector computed as a dot product of the attention weights\n",
    "    \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\n",
    "    \n",
    "    Arguments:\n",
    "    a -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, 2*n_a)\n",
    "    s_prev -- previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)\n",
    "    \n",
    "    Returns:\n",
    "    context -- context vector, input of the next (post-attention) LSTM cell\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Use repeator to repeat s_prev to be of shape (m, Tx, n_s) so that you can concatenate it with all hidden states \"a\" (≈ 1 line)\n",
    "    s_prev = repeator(s_prev)\n",
    "    # Use concatenator to concatenate a and s_prev on the last axis (≈ 1 line)\n",
    "    # For grading purposes, please list 'a' first and 's_prev' second, in this order.\n",
    "    concat = concatenator(inputs =([a,s_prev]))\n",
    "    # Use densor1 to propagate concat through a small fully-connected neural network to compute the \"intermediate energies\" variable e. (≈1 lines)\n",
    "    e = densor1(concat)\n",
    "    # Use densor2 to propagate e through a small fully-connected neural network to compute the \"energies\" variable energies. (≈1 lines)\n",
    "    energies = densor2(e)\n",
    "    # Use \"activator\" on \"energies\" to compute the attention weights \"alphas\" (≈ 1 line)\n",
    "    alphas = activator(energies)\n",
    "    # Use dotor together with \"alphas\" and \"a\" to compute the context vector to be given to the next (post-attention) LSTM-cell (≈ 1 line)\n",
    "    context = dotor([alphas,a])\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, axis=1):\n",
    "    \"\"\"Softmax activation function.\n",
    "    # Arguments\n",
    "        x : Tensor.\n",
    "        axis: Integer, axis along which the softmax normalization is applied.\n",
    "    # Returns\n",
    "        Tensor, output of softmax transformation.\n",
    "    # Raises\n",
    "        ValueError: In case `dim(x) == 1`.\n",
    "    \"\"\"\n",
    "    ndim = K.ndim(x)\n",
    "    if ndim == 2:\n",
    "        return K.softmax(x)\n",
    "    elif ndim > 2:\n",
    "        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "        s = K.sum(e, axis=axis, keepdims=True)\n",
    "        return e / s\n",
    "    else:\n",
    "        raise ValueError('Cannot apply softmax to a tensor that is 1D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_activation_LSTM_cell = LSTM(128, return_state = True) # post-attention LSTM \n",
    "output_layer = Dense(20000, activation=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n",
    "\n",
    "    \n",
    "    # Define the inputs of your model with a shape (Tx,)\n",
    "    # Define s0 (initial hidden state) and c0 (initial cell state)\n",
    "    # for the decoder LSTM with shape (n_s,)\n",
    "    X = Input(shape=(Tx,))\n",
    "    s0 = Input(shape=(n_s,), name='s0')\n",
    "    c0 = Input(shape=(n_s,), name='c0')\n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    # Initialize empty list of outputs\n",
    "    outputs = []\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Step 1: Define your pre-attention Bi-LSTM. (≈ 1 line)\n",
    "    e = embedding_layer(X)\n",
    "    a = Bidirectional(LSTM(units = n_a ,return_sequences = True))(e)\n",
    "    \n",
    "    # Step 2: Iterate for Ty steps\n",
    "    for t in range(Ty):\n",
    "    \n",
    "        # Step 2.A: Perform one step of the attention mechanism to get back the context vector at step t (≈ 1 line)\n",
    "        context = one_step_attention(a, s)\n",
    "        \n",
    "        # Step 2.B: Apply the post-attention LSTM cell to the \"context\" vector.\n",
    "        # Don't forget to pass: initial_state = [hidden state, cell state] (≈ 1 line)\n",
    "        s, _, c = post_activation_LSTM_cell(inputs = context,initial_state = [s,c])\n",
    "        \n",
    "        # Step 2.C: Apply Dense layer to the hidden state output of the post-attention LSTM (≈ 1 line)\n",
    "        out = output_layer(s)\n",
    "        \n",
    "        # Step 2.D: Append \"out\" to the \"outputs\" list (≈ 1 line)\n",
    "        outputs.append(out)\n",
    "    \n",
    "    # Step 3: Create model instance taking three inputs and returning the list of outputs. (≈ 1 line)\n",
    "    model = Model(inputs = [X,s0,c0],outputs = outputs)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model(20, 20,128, 128, 20000, 20000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 20, 50)       68250       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "s0 (InputLayer)                 (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 20, 256)      183296      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_3 (RepeatVector)  (None, 20, 128)      0           s0[0][0]                         \n",
      "                                                                 lstm_5[0][0]                     \n",
      "                                                                 lstm_5[1][0]                     \n",
      "                                                                 lstm_5[2][0]                     \n",
      "                                                                 lstm_5[3][0]                     \n",
      "                                                                 lstm_5[4][0]                     \n",
      "                                                                 lstm_5[5][0]                     \n",
      "                                                                 lstm_5[6][0]                     \n",
      "                                                                 lstm_5[7][0]                     \n",
      "                                                                 lstm_5[8][0]                     \n",
      "                                                                 lstm_5[9][0]                     \n",
      "                                                                 lstm_5[10][0]                    \n",
      "                                                                 lstm_5[11][0]                    \n",
      "                                                                 lstm_5[12][0]                    \n",
      "                                                                 lstm_5[13][0]                    \n",
      "                                                                 lstm_5[14][0]                    \n",
      "                                                                 lstm_5[15][0]                    \n",
      "                                                                 lstm_5[16][0]                    \n",
      "                                                                 lstm_5[17][0]                    \n",
      "                                                                 lstm_5[18][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 20, 384)      0           bidirectional_3[0][0]            \n",
      "                                                                 repeat_vector_3[0][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 repeat_vector_3[1][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 repeat_vector_3[2][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 repeat_vector_3[3][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 repeat_vector_3[4][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 repeat_vector_3[5][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 repeat_vector_3[6][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 repeat_vector_3[7][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 repeat_vector_3[8][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 repeat_vector_3[9][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 repeat_vector_3[10][0]           \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 repeat_vector_3[11][0]           \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 repeat_vector_3[12][0]           \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 repeat_vector_3[13][0]           \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 repeat_vector_3[14][0]           \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 repeat_vector_3[15][0]           \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 repeat_vector_3[16][0]           \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 repeat_vector_3[17][0]           \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 repeat_vector_3[18][0]           \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 repeat_vector_3[19][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 20, 20)       7700        concatenate_3[0][0]              \n",
      "                                                                 concatenate_3[1][0]              \n",
      "                                                                 concatenate_3[2][0]              \n",
      "                                                                 concatenate_3[3][0]              \n",
      "                                                                 concatenate_3[4][0]              \n",
      "                                                                 concatenate_3[5][0]              \n",
      "                                                                 concatenate_3[6][0]              \n",
      "                                                                 concatenate_3[7][0]              \n",
      "                                                                 concatenate_3[8][0]              \n",
      "                                                                 concatenate_3[9][0]              \n",
      "                                                                 concatenate_3[10][0]             \n",
      "                                                                 concatenate_3[11][0]             \n",
      "                                                                 concatenate_3[12][0]             \n",
      "                                                                 concatenate_3[13][0]             \n",
      "                                                                 concatenate_3[14][0]             \n",
      "                                                                 concatenate_3[15][0]             \n",
      "                                                                 concatenate_3[16][0]             \n",
      "                                                                 concatenate_3[17][0]             \n",
      "                                                                 concatenate_3[18][0]             \n",
      "                                                                 concatenate_3[19][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 20, 1)        21          dense_7[0][0]                    \n",
      "                                                                 dense_7[1][0]                    \n",
      "                                                                 dense_7[2][0]                    \n",
      "                                                                 dense_7[3][0]                    \n",
      "                                                                 dense_7[4][0]                    \n",
      "                                                                 dense_7[5][0]                    \n",
      "                                                                 dense_7[6][0]                    \n",
      "                                                                 dense_7[7][0]                    \n",
      "                                                                 dense_7[8][0]                    \n",
      "                                                                 dense_7[9][0]                    \n",
      "                                                                 dense_7[10][0]                   \n",
      "                                                                 dense_7[11][0]                   \n",
      "                                                                 dense_7[12][0]                   \n",
      "                                                                 dense_7[13][0]                   \n",
      "                                                                 dense_7[14][0]                   \n",
      "                                                                 dense_7[15][0]                   \n",
      "                                                                 dense_7[16][0]                   \n",
      "                                                                 dense_7[17][0]                   \n",
      "                                                                 dense_7[18][0]                   \n",
      "                                                                 dense_7[19][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 20, 1)        0           dense_8[0][0]                    \n",
      "                                                                 dense_8[1][0]                    \n",
      "                                                                 dense_8[2][0]                    \n",
      "                                                                 dense_8[3][0]                    \n",
      "                                                                 dense_8[4][0]                    \n",
      "                                                                 dense_8[5][0]                    \n",
      "                                                                 dense_8[6][0]                    \n",
      "                                                                 dense_8[7][0]                    \n",
      "                                                                 dense_8[8][0]                    \n",
      "                                                                 dense_8[9][0]                    \n",
      "                                                                 dense_8[10][0]                   \n",
      "                                                                 dense_8[11][0]                   \n",
      "                                                                 dense_8[12][0]                   \n",
      "                                                                 dense_8[13][0]                   \n",
      "                                                                 dense_8[14][0]                   \n",
      "                                                                 dense_8[15][0]                   \n",
      "                                                                 dense_8[16][0]                   \n",
      "                                                                 dense_8[17][0]                   \n",
      "                                                                 dense_8[18][0]                   \n",
      "                                                                 dense_8[19][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 1, 256)       0           attention_weights[0][0]          \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 attention_weights[1][0]          \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 attention_weights[2][0]          \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 attention_weights[3][0]          \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 attention_weights[4][0]          \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 attention_weights[5][0]          \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 attention_weights[6][0]          \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 attention_weights[7][0]          \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 attention_weights[8][0]          \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 attention_weights[9][0]          \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 attention_weights[10][0]         \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 attention_weights[11][0]         \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 attention_weights[12][0]         \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 attention_weights[13][0]         \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 attention_weights[14][0]         \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 attention_weights[15][0]         \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 attention_weights[16][0]         \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 attention_weights[17][0]         \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 attention_weights[18][0]         \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 attention_weights[19][0]         \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, 128), (None, 197120      dot_2[0][0]                      \n",
      "                                                                 s0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 dot_2[1][0]                      \n",
      "                                                                 lstm_5[0][0]                     \n",
      "                                                                 lstm_5[0][2]                     \n",
      "                                                                 dot_2[2][0]                      \n",
      "                                                                 lstm_5[1][0]                     \n",
      "                                                                 lstm_5[1][2]                     \n",
      "                                                                 dot_2[3][0]                      \n",
      "                                                                 lstm_5[2][0]                     \n",
      "                                                                 lstm_5[2][2]                     \n",
      "                                                                 dot_2[4][0]                      \n",
      "                                                                 lstm_5[3][0]                     \n",
      "                                                                 lstm_5[3][2]                     \n",
      "                                                                 dot_2[5][0]                      \n",
      "                                                                 lstm_5[4][0]                     \n",
      "                                                                 lstm_5[4][2]                     \n",
      "                                                                 dot_2[6][0]                      \n",
      "                                                                 lstm_5[5][0]                     \n",
      "                                                                 lstm_5[5][2]                     \n",
      "                                                                 dot_2[7][0]                      \n",
      "                                                                 lstm_5[6][0]                     \n",
      "                                                                 lstm_5[6][2]                     \n",
      "                                                                 dot_2[8][0]                      \n",
      "                                                                 lstm_5[7][0]                     \n",
      "                                                                 lstm_5[7][2]                     \n",
      "                                                                 dot_2[9][0]                      \n",
      "                                                                 lstm_5[8][0]                     \n",
      "                                                                 lstm_5[8][2]                     \n",
      "                                                                 dot_2[10][0]                     \n",
      "                                                                 lstm_5[9][0]                     \n",
      "                                                                 lstm_5[9][2]                     \n",
      "                                                                 dot_2[11][0]                     \n",
      "                                                                 lstm_5[10][0]                    \n",
      "                                                                 lstm_5[10][2]                    \n",
      "                                                                 dot_2[12][0]                     \n",
      "                                                                 lstm_5[11][0]                    \n",
      "                                                                 lstm_5[11][2]                    \n",
      "                                                                 dot_2[13][0]                     \n",
      "                                                                 lstm_5[12][0]                    \n",
      "                                                                 lstm_5[12][2]                    \n",
      "                                                                 dot_2[14][0]                     \n",
      "                                                                 lstm_5[13][0]                    \n",
      "                                                                 lstm_5[13][2]                    \n",
      "                                                                 dot_2[15][0]                     \n",
      "                                                                 lstm_5[14][0]                    \n",
      "                                                                 lstm_5[14][2]                    \n",
      "                                                                 dot_2[16][0]                     \n",
      "                                                                 lstm_5[15][0]                    \n",
      "                                                                 lstm_5[15][2]                    \n",
      "                                                                 dot_2[17][0]                     \n",
      "                                                                 lstm_5[16][0]                    \n",
      "                                                                 lstm_5[16][2]                    \n",
      "                                                                 dot_2[18][0]                     \n",
      "                                                                 lstm_5[17][0]                    \n",
      "                                                                 lstm_5[17][2]                    \n",
      "                                                                 dot_2[19][0]                     \n",
      "                                                                 lstm_5[18][0]                    \n",
      "                                                                 lstm_5[18][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 20000)        2580000     lstm_5[0][0]                     \n",
      "                                                                 lstm_5[1][0]                     \n",
      "                                                                 lstm_5[2][0]                     \n",
      "                                                                 lstm_5[3][0]                     \n",
      "                                                                 lstm_5[4][0]                     \n",
      "                                                                 lstm_5[5][0]                     \n",
      "                                                                 lstm_5[6][0]                     \n",
      "                                                                 lstm_5[7][0]                     \n",
      "                                                                 lstm_5[8][0]                     \n",
      "                                                                 lstm_5[9][0]                     \n",
      "                                                                 lstm_5[10][0]                    \n",
      "                                                                 lstm_5[11][0]                    \n",
      "                                                                 lstm_5[12][0]                    \n",
      "                                                                 lstm_5[13][0]                    \n",
      "                                                                 lstm_5[14][0]                    \n",
      "                                                                 lstm_5[15][0]                    \n",
      "                                                                 lstm_5[16][0]                    \n",
      "                                                                 lstm_5[17][0]                    \n",
      "                                                                 lstm_5[18][0]                    \n",
      "                                                                 lstm_5[19][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,036,387\n",
      "Trainable params: 2,968,137\n",
      "Non-trainable params: 68,250\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr = 0.005, beta_1 = 0.9,beta_2 = 0.999 , decay = 0.01)\n",
    "model.compile(optimizer = opt , loss = \"sparse_categorical_crossentropy\" ,metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = np.zeros((10, 128))\n",
    "c0 = np.zeros((10, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 8s 812ms/step - loss: 144.7767 - dense_9_loss: 6.2808 - dense_9_accuracy: 0.0000e+00 - dense_9_accuracy_1: 0.0000e+00 - dense_9_accuracy_2: 0.1000 - dense_9_accuracy_3: 0.3000 - dense_9_accuracy_4: 0.4000 - dense_9_accuracy_5: 0.7000 - dense_9_accuracy_6: 0.7000 - dense_9_accuracy_7: 0.7000 - dense_9_accuracy_8: 0.8000 - dense_9_accuracy_9: 0.8000 - dense_9_accuracy_10: 0.8000 - dense_9_accuracy_11: 0.9000 - dense_9_accuracy_12: 0.9000 - dense_9_accuracy_13: 0.9000 - dense_9_accuracy_14: 0.9000 - dense_9_accuracy_15: 0.9000 - dense_9_accuracy_16: 0.9000 - dense_9_accuracy_17: 0.9000 - dense_9_accuracy_18: 0.9000 - dense_9_accuracy_19: 0.9000                                                       \n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 39.0851 - dense_9_loss: 0.2484 - dense_9_accuracy: 0.0000e+00 - dense_9_accuracy_1: 0.0000e+00 - dense_9_accuracy_2: 0.2000 - dense_9_accuracy_3: 0.4000 - dense_9_accuracy_4: 0.5000 - dense_9_accuracy_5: 0.8000 - dense_9_accuracy_6: 0.8000 - dense_9_accuracy_7: 0.8000 - dense_9_accuracy_8: 0.9000 - dense_9_accuracy_9: 0.9000 - dense_9_accuracy_10: 0.9000 - dense_9_accuracy_11: 1.0000 - dense_9_accuracy_12: 1.0000 - dense_9_accuracy_13: 1.0000 - dense_9_accuracy_14: 1.0000 - dense_9_accuracy_15: 1.0000 - dense_9_accuracy_16: 1.0000 - dense_9_accuracy_17: 1.0000 - dense_9_accuracy_18: 1.0000 - dense_9_accuracy_19: 1.0000\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 34.4390 - dense_9_loss: 0.0910 - dense_9_accuracy: 0.0000e+00 - dense_9_accuracy_1: 0.0000e+00 - dense_9_accuracy_2: 0.2000 - dense_9_accuracy_3: 0.4000 - dense_9_accuracy_4: 0.5000 - dense_9_accuracy_5: 0.8000 - dense_9_accuracy_6: 0.8000 - dense_9_accuracy_7: 0.8000 - dense_9_accuracy_8: 0.9000 - dense_9_accuracy_9: 0.9000 - dense_9_accuracy_10: 0.9000 - dense_9_accuracy_11: 1.0000 - dense_9_accuracy_12: 1.0000 - dense_9_accuracy_13: 1.0000 - dense_9_accuracy_14: 1.0000 - dense_9_accuracy_15: 1.0000 - dense_9_accuracy_16: 1.0000 - dense_9_accuracy_17: 1.0000 - dense_9_accuracy_18: 1.0000 - dense_9_accuracy_19: 1.0000                      \n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 29.1089 - dense_9_loss: 0.2277 - dense_9_accuracy: 0.0000e+00 - dense_9_accuracy_1: 0.0000e+00 - dense_9_accuracy_2: 0.2000 - dense_9_accuracy_3: 0.4000 - dense_9_accuracy_4: 0.5000 - dense_9_accuracy_5: 0.8000 - dense_9_accuracy_6: 0.8000 - dense_9_accuracy_7: 0.8000 - dense_9_accuracy_8: 0.9000 - dense_9_accuracy_9: 0.9000 - dense_9_accuracy_10: 0.9000 - dense_9_accuracy_11: 1.0000 - dense_9_accuracy_12: 1.0000 - dense_9_accuracy_13: 1.0000 - dense_9_accuracy_14: 1.0000 - dense_9_accuracy_15: 1.0000 - dense_9_accuracy_16: 1.0000 - dense_9_accuracy_17: 1.0000 - dense_9_accuracy_18: 1.0000 - dense_9_accuracy_19: 1.0000\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 1s 149ms/step - loss: 27.9107 - dense_9_loss: 0.2783 - dense_9_accuracy: 0.0000e+00 - dense_9_accuracy_1: 0.0000e+00 - dense_9_accuracy_2: 0.2000 - dense_9_accuracy_3: 0.4000 - dense_9_accuracy_4: 0.5000 - dense_9_accuracy_5: 0.8000 - dense_9_accuracy_6: 0.8000 - dense_9_accuracy_7: 0.8000 - dense_9_accuracy_8: 0.9000 - dense_9_accuracy_9: 0.9000 - dense_9_accuracy_10: 0.9000 - dense_9_accuracy_11: 1.0000 - dense_9_accuracy_12: 1.0000 - dense_9_accuracy_13: 1.0000 - dense_9_accuracy_14: 1.0000 - dense_9_accuracy_15: 1.0000 - dense_9_accuracy_16: 1.0000 - dense_9_accuracy_17: 1.0000 - dense_9_accuracy_18: 1.0000 - dense_9_accuracy_19: 1.0000\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 1s 143ms/step - loss: 26.7607 - dense_9_loss: 0.2383 - dense_9_accuracy: 0.0000e+00 - dense_9_accuracy_1: 0.0000e+00 - dense_9_accuracy_2: 0.2000 - dense_9_accuracy_3: 0.4000 - dense_9_accuracy_4: 0.5000 - dense_9_accuracy_5: 0.8000 - dense_9_accuracy_6: 0.8000 - dense_9_accuracy_7: 0.8000 - dense_9_accuracy_8: 0.9000 - dense_9_accuracy_9: 0.9000 - dense_9_accuracy_10: 0.9000 - dense_9_accuracy_11: 1.0000 - dense_9_accuracy_12: 1.0000 - dense_9_accuracy_13: 1.0000 - dense_9_accuracy_14: 1.0000 - dense_9_accuracy_15: 1.0000 - dense_9_accuracy_16: 1.0000 - dense_9_accuracy_17: 1.0000 - dense_9_accuracy_18: 1.0000 - dense_9_accuracy_19: 1.0000\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 26.5468 - dense_9_loss: 0.2034 - dense_9_accuracy: 0.0000e+00 - dense_9_accuracy_1: 0.0000e+00 - dense_9_accuracy_2: 0.2000 - dense_9_accuracy_3: 0.4000 - dense_9_accuracy_4: 0.5000 - dense_9_accuracy_5: 0.8000 - dense_9_accuracy_6: 0.8000 - dense_9_accuracy_7: 0.8000 - dense_9_accuracy_8: 0.9000 - dense_9_accuracy_9: 0.9000 - dense_9_accuracy_10: 0.9000 - dense_9_accuracy_11: 1.0000 - dense_9_accuracy_12: 1.0000 - dense_9_accuracy_13: 1.0000 - dense_9_accuracy_14: 1.0000 - dense_9_accuracy_15: 1.0000 - dense_9_accuracy_16: 1.0000 - dense_9_accuracy_17: 1.0000 - dense_9_accuracy_18: 1.0000 - dense_9_accuracy_19: 1.0000                      \n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 1s 146ms/step - loss: 26.0161 - dense_9_loss: 0.1701 - dense_9_accuracy: 0.0000e+00 - dense_9_accuracy_1: 0.0000e+00 - dense_9_accuracy_2: 0.2000 - dense_9_accuracy_3: 0.4000 - dense_9_accuracy_4: 0.5000 - dense_9_accuracy_5: 0.8000 - dense_9_accuracy_6: 0.8000 - dense_9_accuracy_7: 0.8000 - dense_9_accuracy_8: 0.9000 - dense_9_accuracy_9: 0.9000 - dense_9_accuracy_10: 0.9000 - dense_9_accuracy_11: 1.0000 - dense_9_accuracy_12: 1.0000 - dense_9_accuracy_13: 1.0000 - dense_9_accuracy_14: 1.0000 - dense_9_accuracy_15: 1.0000 - dense_9_accuracy_16: 1.0000 - dense_9_accuracy_17: 1.0000 - dense_9_accuracy_18: 1.0000 - dense_9_accuracy_19: 1.0000\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 1s 141ms/step - loss: 25.3656 - dense_9_loss: 0.1563 - dense_9_accuracy: 0.0000e+00 - dense_9_accuracy_1: 0.0000e+00 - dense_9_accuracy_2: 0.2000 - dense_9_accuracy_3: 0.4000 - dense_9_accuracy_4: 0.5000 - dense_9_accuracy_5: 0.8000 - dense_9_accuracy_6: 0.8000 - dense_9_accuracy_7: 0.8000 - dense_9_accuracy_8: 0.9000 - dense_9_accuracy_9: 0.9000 - dense_9_accuracy_10: 0.9000 - dense_9_accuracy_11: 1.0000 - dense_9_accuracy_12: 1.0000 - dense_9_accuracy_13: 1.0000 - dense_9_accuracy_14: 1.0000 - dense_9_accuracy_15: 1.0000 - dense_9_accuracy_16: 1.0000 - dense_9_accuracy_17: 1.0000 - dense_9_accuracy_18: 1.0000 - dense_9_accuracy_19: 1.0000\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 2s 150ms/step - loss: 25.0700 - dense_9_loss: 0.1604 - dense_9_accuracy: 0.0000e+00 - dense_9_accuracy_1: 0.0000e+00 - dense_9_accuracy_2: 0.2000 - dense_9_accuracy_3: 0.4000 - dense_9_accuracy_4: 0.5000 - dense_9_accuracy_5: 0.8000 - dense_9_accuracy_6: 0.8000 - dense_9_accuracy_7: 0.8000 - dense_9_accuracy_8: 0.9000 - dense_9_accuracy_9: 0.9000 - dense_9_accuracy_10: 0.9000 - dense_9_accuracy_11: 1.0000 - dense_9_accuracy_12: 1.0000 - dense_9_accuracy_13: 1.0000 - dense_9_accuracy_14: 1.0000 - dense_9_accuracy_15: 1.0000 - dense_9_accuracy_16: 1.0000 - dense_9_accuracy_17: 1.0000 - dense_9_accuracy_18: 1.0000 - dense_9_accuracy_19: 1.0000          \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7efeadb41b00>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([context,s0,c0],response,epochs=10,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def beam_search_decoder(predictions, top_k = 3):\n",
    "\n",
    "    output_sequences = [([], 0)]\n",
    "    \n",
    "    for token_probs in predictions:\n",
    "        new_sequences = []\n",
    "        token_probs = token_probs.reshape(20000 ,)\n",
    "        for old_seq, old_score in output_sequences:\n",
    "            for char_index in range(len(token_probs)):\n",
    "                new_seq = old_seq + [char_index]\n",
    "                new_score = old_score + math.log(token_probs[char_index])\n",
    "                new_sequences.append((new_seq, new_score))\n",
    "                \n",
    "        output_sequences = sorted(new_sequences, key = lambda val: val[1], reverse = True)\n",
    "        output_sequences = output_sequences[:top_k]\n",
    "        \n",
    "    return output_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [(\"hi\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = tokenizer.texts_to_sequences(s)\n",
    "pad = pad_sequences(seq,maxlen=max_len, truncating=\"post\",padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[236,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0]], dtype=int32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict([pad , np.zeros((1,128)) , np.zeros((1,128))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[2.4002235e-01, 6.4382175e-06, 3.9195258e-02, ..., 6.5357767e-06,\n",
       "         6.2875115e-06, 6.6187172e-06]], dtype=float32),\n",
       " array([[5.0401425e-01, 4.7028820e-07, 3.4023881e-02, ..., 4.8395975e-07,\n",
       "         4.5678064e-07, 5.0095156e-07]], dtype=float32),\n",
       " array([[6.2403727e-01, 1.7086424e-07, 2.6303453e-02, ..., 1.7774663e-07,\n",
       "         1.6766701e-07, 1.8787900e-07]], dtype=float32),\n",
       " array([[7.0929402e-01, 8.4550443e-08, 2.0170171e-02, ..., 8.8587825e-08,\n",
       "         8.4037403e-08, 9.5533025e-08]], dtype=float32),\n",
       " array([[7.7059841e-01, 4.7283983e-08, 1.5664149e-02, ..., 4.9762409e-08,\n",
       "         4.7494677e-08, 5.4538560e-08]], dtype=float32),\n",
       " array([[8.0891657e-01, 3.0728561e-08, 1.2881107e-02, ..., 3.2418459e-08,\n",
       "         3.1046572e-08, 3.5853862e-08]], dtype=float32),\n",
       " array([[8.2998258e-01, 2.3320759e-08, 1.1391275e-02, ..., 2.4635296e-08,\n",
       "         2.3607361e-08, 2.7313760e-08]], dtype=float32),\n",
       " array([[8.4102190e-01, 1.9808629e-08, 1.0644097e-02, ..., 2.0942164e-08,\n",
       "         2.0051266e-08, 2.3190680e-08]], dtype=float32),\n",
       " array([[8.4698159e-01, 1.7963629e-08, 1.0264929e-02, ..., 1.9002963e-08,\n",
       "         1.8171566e-08, 2.0988676e-08]], dtype=float32),\n",
       " array([[8.5047436e-01, 1.6868496e-08, 1.0058992e-02, ..., 1.7852674e-08,\n",
       "         1.7051686e-08, 1.9663466e-08]], dtype=float32),\n",
       " array([[8.5273939e-01, 1.6139269e-08, 9.9354498e-03, ..., 1.7086927e-08,\n",
       "         1.6305300e-08, 1.8772871e-08]], dtype=float32),\n",
       " array([[8.5435122e-01, 1.5607581e-08, 9.8530902e-03, ..., 1.6528402e-08,\n",
       "         1.5762069e-08, 1.8120659e-08]], dtype=float32),\n",
       " array([[8.5558230e-01, 1.5194617e-08, 9.7930254e-03, ..., 1.6094480e-08,\n",
       "         1.5341504e-08, 1.7613830e-08]], dtype=float32),\n",
       " array([[8.5656905e-01, 1.4860376e-08, 9.7462228e-03, ..., 1.5743087e-08,\n",
       "         1.5002486e-08, 1.7204341e-08]], dtype=float32),\n",
       " array([[8.5738528e-01, 1.4582663e-08, 9.7081307e-03, ..., 1.5451118e-08,\n",
       "         1.4722008e-08, 1.6865156e-08]], dtype=float32),\n",
       " array([[8.58073473e-01, 1.43481405e-08, 9.67629999e-03, ...,\n",
       "         1.52046002e-08, 1.44861545e-08, 1.65797189e-08]], dtype=float32),\n",
       " array([[8.58661115e-01, 1.41479894e-08, 9.64923762e-03, ...,\n",
       "         1.49942174e-08, 1.42856038e-08, 1.63369673e-08]], dtype=float32),\n",
       " array([[8.5916668e-01, 1.3976031e-08, 9.6260188e-03, ..., 1.4813584e-08,\n",
       "         1.4113858e-08, 1.6129109e-08]], dtype=float32),\n",
       " array([[8.5960406e-01, 1.3827594e-08, 9.6059591e-03, ..., 1.4657761e-08,\n",
       "         1.3966060e-08, 1.5950198e-08]], dtype=float32),\n",
       " array([[8.5998309e-01, 1.3699123e-08, 9.5885862e-03, ..., 1.4522935e-08,\n",
       "         1.3838441e-08, 1.5795798e-08]], dtype=float32)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ans = beam_search_decoder(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  -5.628117419079653),\n",
       " ([2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  -7.4402936735550265),\n",
       " ([4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  -7.476828381036153)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_word[4]\n",
    "# index_word[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
